{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FBProphet without sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import prophet as fbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets with compound value\n",
    "df_shib = pd.read_csv('C:/Users/deann/Documents/University/Thesis/Thesis_git/datasets/SHIB_data.csv')\n",
    "df_doge = pd.read_csv('C:/Users/deann/Documents/University/Thesis/Thesis_git/datasets/DOGE_data.csv')\n",
    "df_mona = pd.read_csv('C:/Users/deann/Documents/University/Thesis/Thesis_git/datasets/MONA_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOGE\n",
    "df = df_doge\n",
    "dates = df[['Date']]\n",
    "input_feature = df[['Open', 'High', 'Close','Low', 'Adj Close']] \n",
    "input_feature = input_feature.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOGE with com\n",
    "df = df_doge\n",
    "dates = df[['Date']]\n",
    "input_feature = df[['Open', 'High', 'Close','Low', 'Adj Close', 'com']] \n",
    "input_feature = input_feature.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHIB\n",
    "df = df_shib\n",
    "dates = df_shib[['Date']]\n",
    "input_feature = df_shib[['Open', 'High', 'Close','Low', 'Adj Close']] #Ignores the comound value\n",
    "input_feature = input_feature.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHIB with com\n",
    "df = df_shib\n",
    "dates = df[['Date']]\n",
    "input_feature = df[['Open', 'High', 'Close','Low', 'Adj Close', 'com']] \n",
    "input_feature = input_feature.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MONA\n",
    "df = df_mona\n",
    "dates = df_mona[['Date']]\n",
    "input_feature = df_mona[['Open', 'High', 'Close','Low', 'Adj Close']] #Ignores the comound value\n",
    "input_feature = input_feature.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MONA with com\n",
    "df = df_mona\n",
    "dates = df[['Date']]\n",
    "input_feature = df[['Open', 'High', 'Close','Low', 'Adj Close', 'com']] \n",
    "input_feature = input_feature.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for creating the price percentage changes\n",
    "def create_perc_change(data, steps):\n",
    "    y_perc_change = []\n",
    "    data_len = data.shape[0]\n",
    "    for x in range(steps):\n",
    "        y_perc_change.append(np.nan)\n",
    "    for i in range(steps, data_len):\n",
    "        if data[i-steps, 2] == 0:\n",
    "            y_perc_change.append(0)\n",
    "        else:\n",
    "            perc_change = (data[i, 2] - data[i-steps, 2])/data[i-steps, 2]\n",
    "            y_perc_change.append(perc_change)\n",
    "    y_perc_change = np.array(y_perc_change)\n",
    "    return y_perc_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = create_perc_change(input_feature, 1)\n",
    "y_7 = create_perc_change(input_feature, 7)\n",
    "y_14 = create_perc_change(input_feature, 14)\n",
    "y_30 = create_perc_change(input_feature, 30)\n",
    "df['1_day'] = y_1\n",
    "df['7_day'] = y_7\n",
    "df['14_day'] = y_14\n",
    "df['30_day'] = y_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns\n",
    "df_1 = df.rename(columns={\"Date\": \"ds\", \"1_day\": \"y\"})[1:]\n",
    "df_7 = df.rename(columns={\"Date\": \"ds\", \"7_day\": \"y\"})[7:]\n",
    "df_14 = df.rename(columns={\"Date\": \"ds\", \"14_day\": \"y\"})[14:]\n",
    "df_30 = df.rename(columns={\"Date\": \"ds\", \"30_day\": \"y\"})[30:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting test and train sets\n",
    "train_1, test_1 = df_1[:-int(0.15*len(df_1))], df_1[-int(0.15*len(df_1)):]\n",
    "train_7, test_7 = df_7[:-int(0.15*len(df_7))], df_7[-int(0.15*len(df_7)):]\n",
    "train_14, test_14 = df_14[:-int(0.15*len(df_14))], df_14[-int(0.15*len(df_14)):]\n",
    "train_30, test_30 = df_30[:-int(0.15*len(df_30))], df_30[-int(0.15*len(df_30)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the FBProphet model with added regressors\n",
    "def fit_prophet(train):\n",
    "    model = fbp.Prophet()\n",
    "    model.add_regressor('High', standardize=False)\n",
    "    model.add_regressor('Open', standardize=False)\n",
    "    model.add_regressor('Low', standardize=False)\n",
    "    model.add_regressor('Close', standardize=False)\n",
    "    model.add_regressor('Adj Close', standardize=False)\n",
    "    model.add_regressor('com', standardize=False) # Add when using the compound value\n",
    "    model.fit(train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:58:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:58:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:58:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:58:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:58:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:58:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "00:58:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:58:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "#Fitting the four FBProphet models\n",
    "model_1, model_7, model_14, model_30 = fit_prophet(train_1), fit_prophet(train_7), fit_prophet(train_14), fit_prophet(train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function for predicting 1, 7, 14, 30 days with the use of the fitted models\n",
    "def predict_model(test_set, n_days_dataset, dates):\n",
    "    ranges = [x for x in range(-len(test_set[0]),0 , n_days_dataset[0])]\n",
    "    preds = pd.DataFrame({})\n",
    "    pred_yhat_low, pred_yhat_upp, pred_yhat = [], [], []\n",
    "    trues = []\n",
    "    dates_preds = []\n",
    "    for pred in range(len(ranges)):\n",
    "        if ranges[pred] == ranges[-1]:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            predict = test_set[1].predict(test_set[0][ranges[pred]:ranges[pred]+n_days_dataset[0]])\n",
    "            pred_yhat_low.append(predict['yhat_lower'][-1:])\n",
    "            pred_yhat_upp.append(predict['yhat_upper'][-1:])\n",
    "            pred_yhat.append(predict['yhat'][-1:])\n",
    "            t = n_days_dataset[1]['y'][ranges[pred]+n_days_dataset[0]:ranges[pred]+n_days_dataset[0]+1]\n",
    "            trues.append(t)\n",
    "        dates_preds.append(test_set[0]['ds'][ranges[pred]+n_days_dataset[0]:ranges[pred]+n_days_dataset[0]+1])\n",
    "\n",
    "    preds['Date'] = dates_preds\n",
    "    preds['Date'] = preds['Date'].str[:16]\n",
    "    preds['Date'] = preds['Date'].str[-6:]\n",
    "    \n",
    "    preds['pred_yhat_low'] = np.array(pred_yhat_low)\n",
    "    preds['pred_yhat_upp'] = np.array(pred_yhat_upp)\n",
    "    preds['pred_yhat'] = np.array(pred_yhat)\n",
    "    preds['trues'] = np.array(trues)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement a parameter grid for more automatic process\n",
    "param_grid = pd.DataFrame({\n",
    "    'test_set': [(test_1, model_1),(test_7, model_7), (test_14, model_14),  (test_30, model_30)],\n",
    "    'n_days_datasets': [[1, df_1], [7, df_7],[14, df_14],[30, df_30]]\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that runs the predictions, add them to a DataFrame, and export it as a csv file\n",
    "def run_predictions(param_grid, dates):\n",
    "    for n_days_dataset in param_grid['n_days_datasets']:\n",
    "        for test_sets in range(len(param_grid['test_set'])):\n",
    "            print('N_days = ', n_days_dataset[0], 'test_set = ', test_sets)\n",
    "            df_pred = predict_model(param_grid['test_set'][test_sets], n_days_dataset, dates)\n",
    "            df_pred.to_csv(f'C:/Users/deann/Documents/University/Thesis/Thesis_git/Code thesis/data_temp/fbp_mona_with_{n_days_dataset[0]}_daysfuture_model{test_sets}.csv')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_days =  1 test_set =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deann\\AppData\\Local\\Temp\\ipykernel_17452\\905425961.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  preds['trues'] = np.array(trues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_days =  1 test_set =  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deann\\AppData\\Local\\Temp\\ipykernel_17452\\905425961.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  preds['trues'] = np.array(trues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_days =  1 test_set =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deann\\AppData\\Local\\Temp\\ipykernel_17452\\905425961.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  preds['trues'] = np.array(trues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_days =  1 test_set =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deann\\AppData\\Local\\Temp\\ipykernel_17452\\905425961.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  preds['trues'] = np.array(trues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_days =  7 test_set =  0\n",
      "N_days =  7 test_set =  1\n",
      "N_days =  7 test_set =  2\n",
      "N_days =  7 test_set =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deann\\AppData\\Local\\Temp\\ipykernel_17452\\905425961.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  preds['trues'] = np.array(trues)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_days =  14 test_set =  0\n",
      "N_days =  14 test_set =  1\n",
      "N_days =  14 test_set =  2\n",
      "N_days =  14 test_set =  3\n",
      "N_days =  30 test_set =  0\n",
      "N_days =  30 test_set =  1\n",
      "N_days =  30 test_set =  2\n",
      "N_days =  30 test_set =  3\n"
     ]
    }
   ],
   "source": [
    "#Run the predictions\n",
    "predictions = run_predictions(param_grid, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the RMSE score\n",
    "def RMSE(trues, preds, name_model):\n",
    "    RMSE = np.sqrt(mean_squared_error(trues, preds))\n",
    "    #print(f\"Root Mean Square Error of {name_model}: \", RMSE)\n",
    "    return RMSE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 day(s)  7 day(s)  14 day(s)  30 day(s)\n",
      "0  0.021880  0.063001   0.083776   0.126791\n",
      "1  0.042461  0.068087   0.088814   0.116353\n",
      "2  0.065005  0.074796   0.093556   0.117866\n",
      "3  0.129764  0.124093   0.107053   0.048796\n"
     ]
    }
   ],
   "source": [
    "#Defining a function that loads the dataset obtained by the run_predictions() function\n",
    "# and calculates the RMSE value\n",
    "import os\n",
    "def func(value):\n",
    "    return ''.join(value.splitlines())\n",
    "\n",
    "def get_files_RMSE():\n",
    "    df_rmse = pd.DataFrame({})\n",
    "    days = [1,7,14,30]\n",
    "    for x in days:\n",
    "        list_rmse = []\n",
    "        for y in range(len(days)):\n",
    "            path_name = f'C:/Users/deann/Documents/University/Thesis/Thesis_git/Code thesis/data_temp/fbp_mona_with_{x}_daysfuture_model{y}.csv'\n",
    "            df = pd.read_csv(path_name)\n",
    "            var = os.path.splitext(path_name)[0]\n",
    "            var = var[76:]\n",
    "            df['Date'] = df['Date'].apply(lambda x: x[7:17])\n",
    "            #print(len(str(df['trues'][0])) > 23)\n",
    "            if x == 1 or len(str(df['trues'][0])) > 24:\n",
    "                df = df[:-1]\n",
    "                df['trues'] = df['trues'].apply(lambda x: func(x).split('N')[0].split(' ')[-1])\n",
    "                df['trues']= df['trues'].astype(float)\n",
    "            trues = df['trues'].to_list()\n",
    "            preds = df['pred_yhat'].to_list()  \n",
    "\n",
    "            rmse = RMSE(trues, preds, var)\n",
    "            list_rmse.append(rmse)\n",
    "            \n",
    "\n",
    "            #plot(df, trues, preds)\n",
    "        #print('-----------------------------------------------------------------')\n",
    "        df_rmse[f'{x} day(s)'] = np.array(list_rmse)\n",
    "    print(df_rmse)\n",
    "    return  df_rmse\n",
    "\n",
    "rmse = get_files_RMSE()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from personal predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DOGE\n",
    " \n",
    " 1 day(s)  7 day(s)  14 day(s)  30 day(s)\n",
    "0  0.072203  0.257980   0.389725   0.251475\n",
    "1  0.130791  0.280850   0.437439   0.267469\n",
    "2  0.169745  0.190701   0.400563   0.415313\n",
    "3  0.399014  0.324968   0.254224   0.238225\n",
    "\n",
    "DOGE with compound\n",
    "\n",
    " 1 day(s)  7 day(s)  14 day(s)  30 day(s)\n",
    "0  0.073214  0.258481   0.390458   0.255969\n",
    "1  0.154212  0.301503   0.451708   0.328856\n",
    "2  0.239130  0.212785   0.472075   0.482502\n",
    "3  0.336511  0.289349   0.185213   0.127002"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SHIB with compound\n",
    "\n",
    "   1 day(s)  7 day(s)  14 day(s)  30 day(s)\n",
    "0  0.065215  0.103197   0.154832   0.305775\n",
    "1  0.291707  0.303318   0.292218   0.321214\n",
    "2  0.680085  0.754211   0.843993   0.623091\n",
    "3  0.778842  0.824256   0.809345   0.645902\n",
    "\n",
    "SHIB\n",
    " \n",
    " 1 day(s)  7 day(s)  14 day(s)  30 day(s)\n",
    "0  0.060842  0.098527   0.148235   0.302375\n",
    "1  0.224680  0.263372   0.285348   0.305148\n",
    "2  0.544421  0.588904   0.636094   0.585470\n",
    "3  0.856166  0.834231   0.825777   0.767123\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "MONA with compound\n",
    "\n",
    "  1 day(s)  7 day(s)  14 day(s)  30 day(s)\n",
    "0  0.021880  0.063001   0.083776   0.126791\n",
    "1  0.042461  0.068087   0.088814   0.116353\n",
    "2  0.065005  0.074796   0.093556   0.117866\n",
    "3  0.129764  0.124093   0.107053   0.048796\n",
    "\n",
    "MONA\n",
    "\n",
    " 1 day(s)  7 day(s)  14 day(s)  30 day(s)\n",
    "0  0.021894  0.062554   0.082755   0.127301\n",
    "1  0.043306  0.068570   0.088751   0.116593\n",
    "2  0.060296  0.071876   0.090682   0.118073\n",
    "3  0.130840  0.125089   0.109267   0.051321"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c3b67288f80e65b9e22ff20ec38e6fe84e43f60819cfa198ebdaec3c4bdb0f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
